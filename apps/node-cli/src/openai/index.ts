import colors from 'picocolors';
import { Configuration, OpenAIApi } from 'openai';
import { IClient } from '../types';
import Debug from 'debug';
import axios from 'axios';
const debug = Debug('ngptcommit:OpenAiClient');
// è®¾ç½®axiosè¶…æ—¶æ—¶é—´
axios.defaults.timeout = 10000;

class Client implements IClient {
    private openai: OpenAIApi;
    private maxTries: number;

    static instance: Client;

    constructor(apiKey: string, retries: number) {
        debug('åˆå§‹åŒ–openaiæ¥å£, apiKey: ', apiKey);
        const config = new Configuration({
            apiKey,
        });
        this.openai = new OpenAIApi(config);
        this.maxTries = retries;
    }

    static getInstance(apiKey: string, retries: number): IClient {
        if (!Client.instance) {
            Client.instance = new Client(apiKey, retries);
        }
        return Client.instance;
    }

    /**
     * å‘èµ·gpt-3è¯·æ±‚
     * @param prompt 
     * @returns 
     */
    async completions(prompt: string): Promise<string> {
        return this.chatCompletions(prompt, this.maxTries);
    }

    /**
     * 
     * @param prompt 
     * @param retries 
     * @returns 
     */
    async chatCompletions(prompt: string, retries: number): Promise<string> {
        try {
            return this.chat(prompt);
        } catch (error) {
            debug('è°ƒç”¨openaiæ¥å£å¤±è´¥ï¼Œé‡è¯•ä¸­ï¼š', error?.response?.status ?? error.message);
            if (retries > 0) {
                return new Promise((resolve) => {
                    if (error?.response?.status === 429) {
                        // å¦‚æœæ˜¯429é”™è¯¯ï¼Œè¯´æ˜è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œéœ€è¦ç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•
                        setTimeout(() => {
                            this.chatCompletions(prompt, retries - 1).then(res => {
                                resolve(res);
                            })
                        }, 1000);
                    } else {
                        this.chatCompletions(prompt, retries - 1).then(res => {
                            resolve(res);
                        })
                    }

                });
            } else {
                if (error?.response?.status === 429) {
                    console.log(colors.red(`"ğŸ¤– ç”±äºä½ çš„openAIçš„æœ‰è¯·æ±‚æ¬¡æ•°é™åˆ¶ï¼ŒGPT-3 æ‹’ç»äº†ä½ çš„è¯·æ±‚ï¼Œæˆ‘ä»¬å°†å¿½ç•¥è¯¥æ€»ç»“å†…å®¹"`));
                } else {
                    console.log(colors.red(`"ğŸ¤– GPT-3 æ‹’ç»äº†ä½ çš„è¯·æ±‚ï¼Œæˆ‘ä»¬å°†å¿½ç•¥è¯¥æ€»ç»“å†…å®¹"`));
                }
                return "";
            }
        }
    }

    async chat(prompt: string) {
        const response = await this.openai.createChatCompletion({
            model: "gpt-3.5-turbo",
            messages: [{
                role: "user", // system: æœºå™¨äºº, user: ç”¨æˆ·, assistant: åŠ©æ‰‹
                content: prompt
            }]
        });
        // debug('è°ƒç”¨openaiæ¥å£è¿”å›å†…å®¹ï¼š', response.data)
        return response.data.choices[0]?.message?.content ?? "";
    }
}

export default Client;